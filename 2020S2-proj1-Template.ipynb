{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP90049 Introduction to Machine Learning, 2020 Semester 2\n",
    "-----\n",
    "## Project 1: Predicting stroke with Naive Bayes and K-NN\n",
    "-----\n",
    "###### Student Name(s): Wildan Anugrah\n",
    "###### Python version: Python 3.6.9\n",
    "###### Submission deadline: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Project 1 submission. \n",
    "\n",
    "Marking will be applied on the functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # Newer versions\n",
    "import numpy as np\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should transform data into a usable format \n",
    "def convert_class_to_integer(x):\n",
    "        return int(x)\n",
    "\n",
    "def convert_feature_gender(x):\n",
    "        if x == \"Female\": return 0\n",
    "        elif x == \"Male\": return 1\n",
    "        else: return 999\n",
    "\n",
    "def convert_feature_ever_married(x):\n",
    "        if x == \"No\": return 0\n",
    "        elif x == \"Yes\": return 1\n",
    "        else: return 999\n",
    "\n",
    "def convert_feature_work_type(x):\n",
    "        if x == \"Govt_job\": return 0\n",
    "        elif x == \"Private\": return 1\n",
    "        elif x == \"Self-employed\": return 2\n",
    "        elif x == \"children\": return 3\n",
    "        elif x == \"Never_worked\": return 4\n",
    "        else: return 999\n",
    "\n",
    "def convert_feature_Residence_type(x):\n",
    "        if x == \"Rural\": return 0\n",
    "        elif x == \"Urban\": return 1\n",
    "        else: return 999\n",
    "\n",
    "def convert_feature_smoking_status(x):\n",
    "        if x == \"formerly smoked\": return 0\n",
    "        elif x == \"never smoked\": return 1\n",
    "        elif x == \"smokes\": return 2\n",
    "        else: return 999\n",
    "        \n",
    "def categorized_avg_glucose_level(x):\n",
    "    if x <= 70: return 0 #low\n",
    "    elif x <= 200 : return 1 #normal\n",
    "    else: return 2 #high\n",
    "\n",
    "def categorized_bmi(x):\n",
    "    if x < 18.5: return 0 #underweight\n",
    "    elif x < 25: return 1 #healty weight range\n",
    "    elif x < 30: return 2 # overweight\n",
    "    else: return 0 #obese\n",
    "    \n",
    "def categorized_age(x):\n",
    "    if x < 21: return 0 # young\n",
    "    elif x < 40: return 1 #adult\n",
    "    elif x < 60: return 2 #mid age\n",
    "    else: return 4 #old\n",
    "\n",
    "def preprocess(filename):\n",
    "    attributes = []\n",
    "    labels = []\n",
    "    with open(filename, mode='r') as fin:\n",
    "        for line in fin:\n",
    "            atts = line.strip().split(\",\")\n",
    "            attributes.append(atts[:-1]) #all atts, excluding the class\n",
    "            labels.append(atts[-1])\n",
    "    \n",
    "    # remove header\n",
    "    attributes = attributes[1:]\n",
    "    labels = labels[1:]\n",
    "    \n",
    "    attributes_ordinal = []\n",
    "    for x in attributes:\n",
    "        f1, f2, f3, f4, f5, f6, f7, f8, f9, f10 = x\n",
    "        f1 = categorized_avg_glucose_level(float(f1)) # avg_glucose_level\n",
    "        f2 = categorized_bmi(float(f2)) #bmi\n",
    "        f3 = categorized_age(int(f3)) #age\n",
    "        f4 = convert_feature_gender(f4) #gender\n",
    "        f5 = int(f5) #hypertension\n",
    "        f6 = int(f6) #heart_disease\n",
    "        f7 = convert_feature_ever_married(f7) #ever_married\n",
    "        f8 = convert_feature_work_type(f8) #work_type\n",
    "        f9 = convert_feature_Residence_type(f9) #Residence_type\n",
    "        f10 = convert_feature_smoking_status(f10) #smoking_status\n",
    "        x = [f1, f2, f3, f4, f5, f6, f7, f8, f9, f10]\n",
    "        attributes_ordinal.append(x)\n",
    "        \n",
    "    attributes = attributes_ordinal\n",
    "    \n",
    "    labels_ordinal = []\n",
    "    for x in labels:\n",
    "        x = convert_class_to_integer(x)\n",
    "        labels_ordinal.append(x)\n",
    "        \n",
    "    labels = labels_ordinal\n",
    "    \n",
    "    #make sure everything is Integer\n",
    "    attributes = np.array(attributes, dtype='int')\n",
    "    labels = np.array(labels, dtype='int')\n",
    "    \n",
    "    return attributes.tolist(), labels.tolist()\n",
    "\n",
    "attr, label = preprocess(\"stroke_update.csv\")\n",
    "#print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should split a data set into a training set and hold-out test set\n",
    "def split_data(attributes, labels):\n",
    "        return train_test_split(attributes, labels, test_size=0.2)\n",
    "\n",
    "#attributes, labels = preprocess(\"stroke_update.csv\")\n",
    "#split_data(attributes, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model\n",
    "_smoothing = True\n",
    "# Function for counting the frequency of classes to claculate prior probability p(y=i) = n(i)/N\n",
    "def p_y(y):\n",
    "    class_priors = [0]*len(set(y))\n",
    "    for c in y:\n",
    "        class_priors[c]+=1    \n",
    "    return class_priors\n",
    "\n",
    "# Function for likelihood p(x=j|y=i) = n(i,j)/n(i)\n",
    "def p_xy(x,y):\n",
    "    # init dict (over classes) of dict (over features) of dict (over value counts)\n",
    "    outdict = {c:{} for c in y}\n",
    "    for d in outdict.keys():\n",
    "        for f in range(len(x[0])):\n",
    "            outdict[d][f]={}\n",
    "            rng = set([i[f] for i in x])\n",
    "            outdict[d][f] = {v:0 for v in rng}\n",
    "    \n",
    "      \n",
    "    # fill dict with counts\n",
    "    for idx,_ in enumerate(x):\n",
    "        for fidx, _ in enumerate(x[idx]):\n",
    "            outdict[y[idx]][fidx][x[idx][fidx]]+=1\n",
    "    \n",
    "    # normalize, or fill in epsilons as needed\n",
    "    for cl in outdict.keys():\n",
    "        for f in outdict[cl].keys():\n",
    "            for val in outdict[cl][f]:\n",
    "                if outdict[cl][f][val] > 0:\n",
    "                    outdict[cl][f][val] = outdict[cl][f][val] / p_y(y)[cl]\n",
    "                elif outdict[cl][f][val] <= 0 and _smoothing == True:\n",
    "                    outdict[cl][f][val] = (1 + outdict[cl][f][val]) / (p_y(y)[cl] + len(outdict[cl][f]))\n",
    "                    \n",
    "            \n",
    "    return outdict\n",
    "\n",
    "def train(x, y):\n",
    "    return p_xy(x, y)\n",
    "\n",
    "#pxy = train(X_train, y_train)\n",
    "#pp = pprint.PrettyPrinter(indent=4)\n",
    "#pp.pprint(pxy)\n",
    "x, y = preprocess(\"stroke_update.csv\")\n",
    "p_y(y)\n",
    "attr, label = preprocess(\"stroke_update.csv\")\n",
    "#print(float(p_y(y)[0] / len(label)))\n",
    "\n",
    "#list(set(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-96b7d14b94e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#testing purpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moutdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#testing purpose\n",
    "x, y = X_train, y_train\n",
    "outdict = {c:{} for c in y}\n",
    "for d in outdict.keys():\n",
    "    for f in range(len(x[0])):\n",
    "        outdict[d][f]={}\n",
    "        rng = set([i[f] for i in x])\n",
    "        outdict[d][f] = {v:0 for v in rng}\n",
    "#outdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should predict the class for an instance or a set of instances, based on a trained model \n",
    "def predict(x, pc, pxc):\n",
    "    class_probs = []\n",
    "    for y in range(len(pc)):\n",
    "        class_prob=pc[y]/sum(pc)\n",
    "        for fidx, f in enumerate(x):\n",
    "            if f in pxc[y][fidx]:\n",
    "                class_prob = class_prob * pxc[y][fidx][f]\n",
    "        class_probs.append(class_prob)\n",
    "    return class_probs, np.argmax([class_probs])\n",
    "\n",
    "attr, labels = preprocess(\"stroke_update.csv\")\n",
    "X_train, X_test, y_train, y_test = split_data(attr, labels)\n",
    "pxy = p_xy(X_train, y_train)\n",
    "py = p_y(y_train)\n",
    "\n",
    "#for x in X_test:\n",
    "#    print(predict(x, py, pxy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions in terms of metrics\n",
    "# Function to evaluate a set of predictions in terms of metrics\n",
    "from sklearn import metrics\n",
    "def evaluate(pred, true):\n",
    "    CM = metrics.confusion_matrix(true, pred) # Confusion Matrix\n",
    "    Acc = metrics.accuracy_score(true, pred) # Accuracy\n",
    "    precf1 = metrics.precision_recall_fscore_support(true, pred) # Precision, Recall and F1-score\n",
    "    return CM, Acc, precf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "evaluation using training data\n",
      "Confusion Matrix:\n",
      "[[1525  228]\n",
      " [ 245  194]]\n",
      "accuracy: 0.7842153284671532\n",
      "accuracy by sklearn.metric: 0.7842153284671532\n",
      "precision: [0.86158192 0.45971564]\n",
      "recall: [0.86993725 0.44191344]\n",
      "F1: [0.86573943 0.45063879]\n",
      "Zero-R: 0.7997262773722628\n",
      "\n",
      "evaluation using test data\n",
      "Confusion Matrix:\n",
      "[[383  56]\n",
      " [ 59  50]]\n",
      "accuracy: 0.7901459854014599\n",
      "accuracy by sklearn.metric: 0.7901459854014599\n",
      "precision: [0.86651584 0.47169811]\n",
      "recall: [0.87243736 0.4587156 ]\n",
      "F1: [0.86946652 0.46511628]\n",
      "Zero-R: 0.801094890510949\n"
     ]
    }
   ],
   "source": [
    "attr, labels = preprocess(\"stroke_update.csv\")\n",
    "X_train, X_test, y_train, y_test = split_data(attr, labels)\n",
    "pxy = p_xy(X_train, y_train)\n",
    "py = p_y(y_train)\n",
    "\n",
    "def calculateZeroR(y):\n",
    "    a = p_y(y)\n",
    "    if((a[0] / len(y)) > (a[1] / len(y))): return 0\n",
    "    else: return 1\n",
    "    \n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0\n",
    "    for i in range(len(row1)):\n",
    "        for j in range(len(row1[i])):\n",
    "            distance += (row1[i][j] - row2[j])**2\n",
    "    return 4\n",
    "\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "#print(get_neighbors(X_train, X_test, 1))\n",
    "    \n",
    "print(\"\\nevaluation using training data\")\n",
    "zeroRTrain = calculateZeroR(y_train)\n",
    "zeroRTest = calculateZeroR(y_test)\n",
    "\n",
    "correct = 0\n",
    "correctZeroR = 0\n",
    "preds = []\n",
    "for i in range(len(X_train)):\n",
    "    prediction = predict(X_train[i], py, pxy)[1]\n",
    "    correct = correct + int(prediction==y_train[i])\n",
    "    correctZeroR = correctZeroR + int(zeroRTrain==y_train[i])\n",
    "    preds.append(prediction)                 \n",
    "CM, Acc, precf1 = evaluate(preds, y_train)\n",
    "\n",
    "print(\"Confusion Matrix:\\n{}\\naccuracy: {}\\naccuracy by sklearn.metric: {}\\nprecision: {}\\nrecall: {}\\nF1: {}\\nZero-R: {}\".format(CM,\n",
    "                                                correct / len(X_train), \n",
    "                                                Acc,\n",
    "                                                precf1[0],\n",
    "                                                precf1[1],\n",
    "                                                precf1[2],\n",
    "                                                correctZeroR / len(X_train)))\n",
    "\n",
    "# predict on test\n",
    "print(\"\\nevaluation using test data\")\n",
    "correctZeroR = 0\n",
    "correct = 0\n",
    "preds = []\n",
    "for i in range(len(X_test)):\n",
    "    prediction = predict(X_test[i], py, pxy)[1]\n",
    "    correct = correct + int(prediction==y_test[i])\n",
    "    correctZeroR = correctZeroR + int(zeroRTest==y_test[i])\n",
    "    preds.append(prediction)            \n",
    "CM, Acc, precf1 = evaluate(preds, y_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n{}\\naccuracy: {}\\naccuracy by sklearn.metric: {}\\nprecision: {}\\nrecall: {}\\nF1: {}\\nZero-R: {}\".format(CM, \n",
    "                                                correct / len(X_test), \n",
    "                                                Acc,\n",
    "                                                precf1[0],\n",
    "                                                precf1[1],\n",
    "                                                precf1[2],\n",
    "                                                correctZeroR / len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN implementation\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "preds = classifier.predict(X_test)\n",
    "#preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[364  75]\n",
      " [ 72  37]]\n",
      "accuracy: 0.7317518248175182\n",
      "precision: [0.83486239 0.33035714]\n",
      "recall: [0.82915718 0.33944954]\n",
      "F1: [0.832      0.33484163]\n"
     ]
    }
   ],
   "source": [
    "CM, Acc, precf1 = evaluate(preds, y_test)\n",
    "print(\"Confusion Matrix:\\n{}\\naccuracy: {}\\nprecision: {}\\nrecall: {}\\nF1: {}\".format(CM, \n",
    "                                                Acc,\n",
    "                                                precf1[0],\n",
    "                                                precf1[1],\n",
    "                                                precf1[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knnImplementation(K):\n",
    "    \n",
    "    print(\"\\n\\nK = \", K)\n",
    "    \n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    classifier = KNeighborsClassifier(n_neighbors=K)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    preds = classifier.predict(X_test)\n",
    "    zeroRTest = calculateZeroR(y_test)\n",
    "    correctZeroR = 0\n",
    "    correct = 0\n",
    "    for i in range(len(X_test)):\n",
    "        correctZeroR = correctZeroR + int(zeroRTest==y_test[i])\n",
    "        correct = correct + int(preds[i]==y_test[i])\n",
    "\n",
    "    CM, Acc, precf1 = evaluate(preds, y_test)\n",
    "    print(\"Confusion Matrix:\\n{}\\naccuracy: {}\\naccuracy by sklearn.metric: {}\\nprecision: {}\\nrecall: {}\\nF1: {}\\nZero-R: {}\".format(CM,\n",
    "                                                    correct / len(X_test), \n",
    "                                                    Acc,\n",
    "                                                    precf1[0],\n",
    "                                                    precf1[1],\n",
    "                                                    precf1[2],\n",
    "                                                    correctZeroR / len(X_test)))\n",
    "    \n",
    "def calculateKNN(K):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "    classifier = KNeighborsClassifier(n_neighbors=K)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    preds = classifier.predict(X_test)\n",
    "    correct = 0\n",
    "    for i in range(len(X_test)):\n",
    "        correct = correct + int(preds[i]==y_test[i])\n",
    "    \n",
    "    return correct / len(X_test)\n",
    "    \n",
    "def findTheBestKNN():\n",
    "    highestAcc = 0.0\n",
    "    bestK = 0\n",
    "    resultKNN = 0\n",
    "    listOfKNN = []\n",
    "    for i in range(169):\n",
    "        resultKNN = calculateKNN((i + 1))\n",
    "        listOfKNN.append(resultKNN)\n",
    "        if(highestAcc < resultKNN):\n",
    "            highestAcc = resultKNN\n",
    "            bestK = i\n",
    "    \n",
    "    return highestAcc, (bestK + 1), listOfKNN\n",
    "\n",
    "\n",
    "#evaluate_knnImplementation(K=1) \n",
    "#print(findTheBestKNN())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions (you may respond in a cell or cells below):\n",
    "\n",
    "You should respond to questions 1-4. In question 2 (b) you can choose between two options. A response to a question should take about 100--200 words, and make reference to the data wherever possible.\n",
    "\n",
    "### Question 1: Data exploration\n",
    "\n",
    "- a) Explore the data and summarise different aspects of the data. Can you see any interesting characteristic in features, classes or categories? What is the main issue with the data? Considering the issue, how would the Naive Bayes classifier work on this data? Discuss your answer based on the Naive Bayes' formulation.\n",
    "- b) Is accuracy an appropriate metric to evaluate the models created for this data? Justify your answer. Explain which metric(s) would be more appropriate, and contrast their utility against accuracy. [no programming required]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) It can be seen that the number of instance with interesting class (the number of patient got stroke) is fewer than the the number of instance with uninteresting class (the number of patient had not stroke). The number of data with uninteresting class is 2192 and the number of data with interesting class is 548 (it is almost 4:1). Considering this issue, it would affect the accuracy of prediction with Naive Bayes classifier, because, we want to predict the probability of patient got stroke based on the data we get. However, comparison of the number of data for the patient who got stroke is so limited rather than the data for patient did not get stroke. \n",
    "\n",
    "- b) Considering the issue that we found in this data, it could a problem for the accuracy of this model. In this case, we would like to predict of people getting stroke. However, the number of people had no stroke is higher than the number of people got stroke. the comparison is almost 4:1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Naive Bayes concepts and formulation\n",
    "\n",
    "- a) Explain the independence assumption underlying Naive Bayes. What are the advantages and disadvantages of this assumption? Elaborate your answers using the features of the provided data. [no programming required]\n",
    "- b) Implement the Naive Bayes classifier. You need to decide how you are going to apply Naive Bayes for nominal and numeric attributes. You can combine both Gaussian and Categorical Naive Bayes (option 1) or just using Categorical Naive Bayes (option 2). Explain your decision. For Categorical Naive Bayes, you can choose either epsilon or Laplace smoothing for this calculation. Evaluate the classifier using accuracy and appropriate metric(s) on test data. Explain your observations on how the classifiers have performed based on the metric(s). Discuss the performance of the classifiers in comparison with the Zero-R baseline.\n",
    "- c) Explain the difference between epsilon and Laplace smoothing. [no programming required]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) Firstly, there some advantages. First of all, the provided data can be calculated by Naive Bayes as long as the data in the useful format. Second, with this number of data (2740) it helps the model to calculate precisely. However, the data is imbalanced. We know that we would like to predict the data with interesting class. there is only 548 instances labeled 1 (A patient with strokes). This issue would affect the accuracy of the result from the model. \n",
    "\n",
    "- b) I chose option 2 (Categorical Naive Bayes) because, it can be seen that mostly the provided data can be categorized. And also, I believe, it is easier to maintain programatically rather than using Gaussian Naive Bayes. It can be done by combined both Gaussian and Categorical. However, I prefer to chose categorical, I convert some data such as age or bmi feature to categorical value. I found some unseen data, so then I decided to do smoothing. I chose Lapalce smoothing, because it has a large data, more than 2000 data. So then, it can be more appropriate rather than using Epsilon smoothing. As we can see, that the result of Zero-R baseline is quite similar with Naive Bayes models calculation in this case. \n",
    "\n",
    "- c) It is known that epsilon smoothing is the simplest approach. However, considering the provided data, there is a problem to decide the number of epsilon. Because, there is a probabilty of tie issue. On the other hand, laplace smoothing is more approprite than using epsilon smoothing because of some reason. First, the characteristic of provided data which is large number. So then, we can use laplace smoothing more effective due reducing variance of NB classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Model Comparison\n",
    "- a) Implement the K-NN classifier, and find the optimal value for K. \n",
    "- b) Based on the obtained value for K in question 4 (a), evaluate the classifier using accuracy and chosen metric(s) on test data. Explain your observations on how the classifiers have performed based on the metric(s). Discuss the performance of the classifiers in comparison with the Zero-R baseline.\n",
    "- c) Is K-NN sensitive to imbalanced data? Justify your answer. [no programming required]\n",
    "- d) Compare the classifiers (Naive Bayes and K-NN) based on metrics' results. Provide a comparatory discussion on the results. [no programming required]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- a) implement the K-NN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "K =  6\n",
      "Confusion Matrix:\n",
      "[[423  16]\n",
      " [ 89  20]]\n",
      "accuracy: 0.8083941605839416\n",
      "accuracy by sklearn.metric: 0.8083941605839416\n",
      "precision: [0.82617188 0.55555556]\n",
      "recall: [0.96355353 0.18348624]\n",
      "F1: [0.88958991 0.27586207]\n",
      "Zero-R: 0.801094890510949\n",
      "max:  0.8083941605839416  min:  0.7317518248175182\n"
     ]
    }
   ],
   "source": [
    "# K-NN implementation\n",
    "highestAcc, bestK, listOfKNN = findTheBestKNN()\n",
    "#print(\"KNN HighestAcc: \", highestAcc, \"\\nBest-K: \", bestK)\n",
    "evaluate_knnImplementation(K=bestK)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "#pp.pprint(listOfKNN)\n",
    "\n",
    "print(\"max: \", max(listOfKNN), \" min: \", min(listOfKNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- b) As we implemented K-NN, it can be found that the optimal value for K is 10 where the accuracy is 0.8266423357664233. It is slightly similar with the number accuracy with Zero-R model which is 0.815693430656934. \n",
    "\n",
    "- c) As we implemented K-NN, it can be seen that KNN is not sensitive to imbalanced data. Considering the provided data using evaluate_knnImplementation, it is shown that the range of data between 0.7317518248175182 and 0.8083941605839416. \n",
    "\n",
    "- d) Comparing the accuracy betweem Naive Bayes and K-NN is"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
